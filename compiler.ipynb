{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2230386",
   "metadata": {},
   "source": [
    "### Left recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57347f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': ['T', 'F', \"+TS'\", \"-FS'\", 'ε'], 'T': ['F', \"*FT'\", 'ε'], 'F': ['(S)', 'id'], \"S'\": ['S+T', 'S-F', \"S'\"], \"T'\": ['T*F', \"T'\"]}\n"
     ]
    }
   ],
   "source": [
    "def remove_left_recursion(grammar):\n",
    "    non_terminals = list(grammar.keys())\n",
    "    \n",
    "    for A in non_terminals:\n",
    "        productions = grammar[A]\n",
    "        new_productions = []\n",
    "        recursive_productions = []\n",
    "        \n",
    "        for production in productions:\n",
    "            if production.startswith(A):\n",
    "                recursive_productions.append(production)\n",
    "            else:\n",
    "                new_productions.append(production)\n",
    "        \n",
    "        if recursive_productions:\n",
    "            new_A = A + \"'\"\n",
    "            new_productions += [p[1:] + new_A for p in recursive_productions]\n",
    "            new_productions.append('ε')\n",
    "            grammar[A] = new_productions\n",
    "            grammar[new_A] = recursive_productions + [new_A]\n",
    "    \n",
    "    return grammar\n",
    "\n",
    "# Example Grammar\n",
    "grammar = {\n",
    "    'S': ['T', 'F', 'S+T', 'S-F'],\n",
    "    'T': ['F', 'T*F'],\n",
    "    'F': ['(S)', 'id']\n",
    "}\n",
    "\n",
    "new_grammar = remove_left_recursion(grammar)\n",
    "print(new_grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dbc01",
   "metadata": {},
   "source": [
    "### Left factoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53a21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Grammar:\n",
      "S -> abc | abd | aef | aeg\n",
      "A -> abc | abd | aef | aeg\n",
      "\n",
      "Left Factored Grammar:\n",
      "S -> aX\n",
      "X -> bc | bd | ef | eg\n",
      "A -> aX\n"
     ]
    }
   ],
   "source": [
    "def left_factor(grammar):\n",
    "    factored_grammar = {}\n",
    "    \n",
    "    for non_terminal, productions in grammar.items():\n",
    "        common_prefix = get_common_prefix(productions)\n",
    "        \n",
    "        if common_prefix:\n",
    "            factored_grammar[non_terminal] = [common_prefix + 'X']\n",
    "            new_productions = [p[len(common_prefix):] or 'ε' for p in productions]\n",
    "            factored_grammar['X'] = new_productions\n",
    "        \n",
    "        else:\n",
    "            factored_grammar[non_terminal] = productions\n",
    "    \n",
    "    return factored_grammar\n",
    "\n",
    "def get_common_prefix(productions):\n",
    "    if not productions:\n",
    "        return None\n",
    "    \n",
    "    common_prefix = ''\n",
    "    min_length = min(len(p) for p in productions)\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        if all(p[i] == productions[0][i] for p in productions):\n",
    "            common_prefix += productions[0][i]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return common_prefix\n",
    "\n",
    "def print_grammar(grammar):\n",
    "    for non_terminal, productions in grammar.items():\n",
    "        print(f\"{non_terminal} -> {' | '.join(productions)}\")\n",
    "\n",
    "# Example usage\n",
    "original_grammar = {\n",
    "    'S': ['abc', 'abd', 'aef', 'aeg'],\n",
    "    'A': ['abc', 'abd', 'aef', 'aeg'],\n",
    "}\n",
    "\n",
    "factored_grammar = left_factor(original_grammar)\n",
    "\n",
    "print(\"Original Grammar:\")\n",
    "print_grammar(original_grammar)\n",
    "print(\"\\nLeft Factored Grammar:\")\n",
    "print_grammar(factored_grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9237da7",
   "metadata": {},
   "source": [
    "### First and follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9039b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Grammar:\n",
      "S -> abc | abd | aef | aeg\n",
      "A -> abc | abd | aef | aeg\n",
      "\n",
      "First and Follow Sets:\n",
      "A: First = {'a'}, Follow = set()\n",
      "S: First = {'a'}, Follow = {'$'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.setrecursionlimit(60)\n",
    "\n",
    "def first(string):\n",
    "    first_ = set()\n",
    "    if string in non_terminals:\n",
    "        alternatives = productions_dict[string]\n",
    "\n",
    "        for alternative in alternatives:\n",
    "            first_2 = first(alternative)\n",
    "            first_ = first_ | first_2\n",
    "\n",
    "    elif string in terminals:\n",
    "        first_ = {string}\n",
    "\n",
    "    elif string == '' or string == '@':\n",
    "        first_ = {'@'}\n",
    "\n",
    "    else:\n",
    "        first_2 = first(string[0])\n",
    "        if '@' in first_2:\n",
    "            i = 1\n",
    "            while '@' in first_2:\n",
    "                first_ = first_ | (first_2 - {'@'})\n",
    "                if string[i:] in terminals or string[i:] == '':\n",
    "                    first_ = first_ | {string[i:]}\n",
    "                    break\n",
    "                first_2 = first(string[i:])\n",
    "                first_ = first_ | first_2 - {'@'}\n",
    "                i += 1\n",
    "        else:\n",
    "            first_ = first_ | first_2\n",
    "\n",
    "    return first_\n",
    "\n",
    "def follow(nT):\n",
    "    follow_ = set()\n",
    "    prods = productions_dict.items()\n",
    "    if nT == starting_symbol:\n",
    "        follow_ = follow_ | {'$'}\n",
    "    for nt, rhs in prods:\n",
    "        for alt in rhs:\n",
    "            for i, char in enumerate(alt):\n",
    "                if char == nT:\n",
    "                    following_str = alt[i + 1:]\n",
    "                    if following_str == '':\n",
    "                        if nt == nT:\n",
    "                            continue\n",
    "                        else:\n",
    "                            follow_ = follow_ | follow(nt)\n",
    "                    else:\n",
    "                        follow_2 = first(following_str)\n",
    "                        if '@' in follow_2:\n",
    "                            follow_ = follow_ | follow_2 - {'@'}\n",
    "                            follow_ = follow_ | follow(nt)\n",
    "                        else:\n",
    "                            follow_ = follow_ | follow_2\n",
    "\n",
    "    return follow_\n",
    "\n",
    "def left_factorize(grammar):\n",
    "    new_productions = {}\n",
    "    for non_terminal, alternatives in grammar.items():\n",
    "        common_prefix = os.path.commonprefix(alternatives)\n",
    "        if common_prefix:\n",
    "            suffix_productions = [alt[len(common_prefix):] for alt in alternatives]\n",
    "            new_non_terminal = non_terminal + \"'\"\n",
    "            new_productions[non_terminal] = [common_prefix + new_non_terminal]\n",
    "            new_productions[new_non_terminal] = suffix_productions\n",
    "\n",
    "    return new_productions\n",
    "\n",
    "# Sample Grammar\n",
    "original_grammar = {\n",
    "    'S': ['abc', 'abd', 'aef', 'aeg'],\n",
    "    'A': ['abc', 'abd', 'aef', 'aeg']\n",
    "}\n",
    "\n",
    "# Fix input and output\n",
    "terminals = {'a', 'b', 'c', 'd', 'e', 'f', 'g'}\n",
    "non_terminals = {'S', 'A'}\n",
    "starting_symbol = 'S'\n",
    "\n",
    "productions_dict = original_grammar\n",
    "\n",
    "# Display Original Grammar\n",
    "print(\"Original Grammar:\")\n",
    "for non_terminal, alternatives in original_grammar.items():\n",
    "    print(f\"{non_terminal} -> {' | '.join(alternatives)}\")\n",
    "\n",
    "# Calculate and Display First and Follow Sets\n",
    "print(\"\\nFirst and Follow Sets:\")\n",
    "for non_terminal in non_terminals:\n",
    "    first_set = first(non_terminal)\n",
    "    follow_set = follow(non_terminal)\n",
    "    print(f\"{non_terminal}: First = {first_set}, Follow = {follow_set}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ba247",
   "metadata": {},
   "source": [
    "### Parsing tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c82fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Tree:\n",
      "Expression\n",
      "  Expression\n",
      "    Number: 3\n",
      "    Operator: +\n",
      "    Number: 5\n",
      "  Operator: *\n",
      "  Number: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def __str__(self, level=0):\n",
    "        result = \"  \" * level + str(self.value) + \"\\n\"\n",
    "        for child in self.children:\n",
    "            result += child.__str__(level + 1)\n",
    "        return result\n",
    "\n",
    "def parse_expression(tokens):\n",
    "    root = Node(\"Expression\")\n",
    "    current_node = root\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "            current_node.add_child(Node(\"Number: \" + token))\n",
    "        elif token in \"+-*/\":\n",
    "            current_node.add_child(Node(\"Operator: \" + token))\n",
    "        elif token == \"(\":\n",
    "            new_node = Node(\"Expression\")\n",
    "            current_node.add_child(new_node)\n",
    "            current_node = new_node\n",
    "        elif token == \")\":\n",
    "            current_node = root  # Move back up one level\n",
    "\n",
    "    return root\n",
    "\n",
    "def display_tree(tree):\n",
    "    print(\"Parsing Tree:\")\n",
    "    print(tree)\n",
    "\n",
    "# Example input\n",
    "expression_tokens = [\"(\", \"3\", \"+\", \"5\", \")\", \"*\", \"2\"]\n",
    "\n",
    "# Parse and display the tree\n",
    "parsing_tree = parse_expression(expression_tokens)\n",
    "display_tree(parsing_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffdec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
